{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e899361a-1216-4170-911e-5f0df8da8b09",
   "metadata": {},
   "source": [
    "# Multithreading in Julia\n",
    "\n",
    "_Part of this notebook is inspired by the material of th [Julia for HPC Course @ UCL ARC ](https://github.com/carstenbauer/JuliaUCL24) by Carsten Bauer._\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048538f-2175-4a14-87af-5aba4b12841e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running this cell is important to make sure we install all the necessary packages.\n",
    "using Pkg\n",
    "Pkg.activate(@__DIR__)\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c6fd7d-70bb-47c5-8503-f6c32f6e1dfa",
   "metadata": {},
   "source": [
    "## Thread pinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1af96a-bfd4-4846-89e9-07e49d1d4e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using ThreadPinning\n",
    "pinthreads(:cores)\n",
    "threadinfo(; slurm=ThreadPinning.SLURM.isslurmjob())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c7002f-faa6-4d15-b3bb-137f04153b84",
   "metadata": {},
   "source": [
    "## Spawning parallel tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d086025-6330-49c9-8c38-b7a9d86fc0ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Base.Threads\n",
    "\n",
    "@show nthreads();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6896cf1-52dd-4c09-8ff0-20041ef49dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@time t = @spawn begin # `@spawn` returns right away\n",
    "    sleep(2)\n",
    "    3+3\n",
    "end\n",
    "\n",
    "@time fetch(t) # `fetch` waits for the task to finish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a4ab8b-7519-4736-8b03-47a8a020740c",
   "metadata": {},
   "source": [
    "## Exercise: task-based parallelised `map`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc35b67e-5279-46f4-a728-f232495a0b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using LinearAlgebra, BenchmarkTools\n",
    "\n",
    "BLAS.set_num_threads(1) # Fix number of BLAS threads\n",
    "\n",
    "# Exercise: define a task-based `map` function, using tasks\n",
    "function tmap(fn, itr)\n",
    "    # Define a variable called `tasks`, which is a vector, which for all element `x` of `itr` holds the task running `fn(x)`\n",
    "    # Hint #1: you can use `map(f, itr)` to  apply the function `f` on each element of `itr`.\n",
    "    # Hint #2: anonymous functions `x -> f(x)` are a convenient syntax for defining one-line functions inside other functions.\n",
    "    tasks = map(i -> ..., itr)\n",
    "    # Call `fetch` on all elements of `tasks` to collect the result of all spawned tasks, and return the result.\n",
    "    # Hint: you can use broadcasting for running a function element-wise on an iterator.\n",
    "    return # ...\n",
    "end\n",
    "\n",
    "M = [rand(100,100) for i in 1:(8 * nthreads())];\n",
    "\n",
    "@btime  map(svdvals, $M) samples=10 evals=3;\n",
    "@btime tmap(svdvals, $M) samples=10 evals=3;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88358e2d-0b6c-4d18-8ebf-fa3406f86043",
   "metadata": {},
   "source": [
    "***Bonus***: do you see any difference if you increase the number of BLAS threads?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36627189-000e-45ee-84d9-b49665e2b333",
   "metadata": {},
   "source": [
    "## Exercise: multi-threaded `for` loop (reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e01fc54-7c4a-42ff-a3aa-a2e202c97d78",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong><tt>ChunkSplitters.jl</tt></strong> <br />The simple package <a href=\"https://juliafolds2.github.io/ChunkSplitters.jl/stable/\" class=\"alert-link\"><tt>ChunkSplitters.jl</tt></a> provides the function <a href=\"https://juliafolds2.github.io/ChunkSplitters.jl/stable/references/#ChunkSplitters.chunks\" class=\"alert-link\"><tt>chunks</tt></a> which returns an iterator with chunks of the input data, which you can then use for a threaded <tt>for</tt> loop, or to spawn tasks in parallel.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c22a87-956a-4723-a5bd-c4ef0c10a999",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong>Computing <tt>sum</tt> after applying function elementwise</strong> <br />The <a href=\"https://docs.julialang.org/en/v1/base/collections/#Base.sum\" class=\"alert-link\"><tt>sum</tt></a> function takes optionally as first argument a function to apply elementwise to all elements of the input iteartor, before computing the sum.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcfbc38-3f2c-4f2e-b354-8d66bec8b31e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using ChunkSplitters, Base.Threads, BenchmarkTools\n",
    "\n",
    "# Define a function which computes the sum of the elements of an iterator `data` in parallel,\n",
    "# after applying a user-supplied function `fn` element-wise\n",
    "function sum_threads(fn, data; nchunks=nthreads())\n",
    "    psums = zeros(eltype(data), nchunks)\n",
    "    # Hint: place `@threads` in front of the `for` loop run it multi-threaded.\n",
    "    @threads for (c, elements) in enumerate(chunks(data; n=nchunks))\n",
    "        # Hint: each element of `psums` should be the sum of `fn` applied\n",
    "        # elelementwise to all the items of the current iteration.\n",
    "        psums[c] = # .....\n",
    "    end\n",
    "    return # .....\n",
    "end\n",
    "\n",
    "v = randn(20_000_000);\n",
    "\n",
    "@btime sum(sin, $v);\n",
    "\n",
    "@btime sum_threads(sin, $v);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50040792-a994-43f4-8a18-12a48c6192d1",
   "metadata": {},
   "source": [
    "***Bonus***: `Threads.@threads` lets you choose the scheduler with a symbol between `@threads` and `for`, see [its docstring](https://docs.julialang.org/en/v1/base/multi-threading/#Base.Threads.@threads) for more details.  Do you see differences if you change the scheduler type?  Remember you can choose between `:dynamic` (currently the default if omitted), `:greedy` (only available when using Julia v1.11+), and `:static`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c506bc51-db01-471b-abb6-e332bc124ae3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong>Syntax tip</strong> <br />The <a href=\"https://docs.julialang.org/en/v1/base/base/#do\" class=\"alert-link\"><tt>do</tt>-block syntax</a> allows you to write (possibly long) anonymous functions and automatically pass them as first argument to functions which take another function as first argument. This syntax is often used in conjunction with <a href=\"https://docs.julialang.org/en/v1/base/collections/#Base.map\" class=\"alert-link\"><tt>map</tt></a>, which takes a function as first argument.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e37ec-1bb7-441a-b3ac-27b9bac803b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function which does the parallel sum using `map` + `@spawn`\n",
    "# as we've done above, instead of `@threads for`.\n",
    "function sum_map_spawn(fn, data; nchunks=nthreads())\n",
    "    ts = map(chunks(data, n=nchunks)) do elements\n",
    "        # ....\n",
    "    end\n",
    "    return # ....\n",
    "end\n",
    "\n",
    "@btime sum_map_spawn(sin, $v);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9d0745-0c49-45f2-b35b-f44cfd7e9cb2",
   "metadata": {},
   "source": [
    "### Bonus: using OhMyThreads.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be528279-904c-4284-87a9-74099997fcdd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong><tt>OhMyThreads.jl</tt></strong> <br />The package <a href=\"https://juliafolds2.github.io/OhMyThreads.jl/\" class=\"alert-link\"><tt>OhMyThreads.jl</tt></a> provides user-friendly constructs for task-based multithreaded computing.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19072e0f-e688-426b-b4d4-90e030856001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using OhMyThreads: @tasks\n",
    "\n",
    "# Define a function which uses `OhMyThreads`' `@tasks` instead of `Threads.@threads`.\n",
    "function sum_tasks(fn, data; nchunks=nthreads())\n",
    "    psums = zeros(eltype(data), nchunks)\n",
    "    # Hint: this function will look a lot like `sum_threads` above,\n",
    "    # but with `@tasks` instead of `@threads`.\n",
    "    @tasks for (c, elements) in enumerate(chunks(data; n=nchunks))\n",
    "        psums[c] = # ....\n",
    "    end\n",
    "    return # ....\n",
    "end\n",
    "\n",
    "@btime sum_tasks(sin, $v);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcad460a-3f61-4020-bba1-3cb04c910606",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong>Parallel <tt>mapreduce</tt> with <tt>OhMyThreads.jl</tt></strong> <br /><tt>OhMyThreads.jl</tt> provides also a function called <a href=\"https://juliafolds2.github.io/OhMyThreads.jl/stable/refs/api/#OhMyThreads.tmapreduce\" class=\"alert-link\"><tt>tmapreduce</tt></a> which does a task-based multi-threaded <a href=\"https://docs.julialang.org/en/v1/base/collections/#Base.mapreduce-Tuple%7BAny,%20Any,%20Any%7D\" class=\"alert-link\"><tt>mapreduce</tt></a> operation, pretty much what we wanted to do above.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c9bc38-11cf-4fca-b314-1b7a08ecb7a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using OhMyThreads: tmapreduce\n",
    "\n",
    "# Call `tmapreduce` applying the function `sin` to all elements of `v`\n",
    "# and then take the sum of all these elements.\n",
    "@btime tmapreduce(..., ..., $v);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e385c3f-0650-48a5-bd48-b55610a752d7",
   "metadata": {},
   "source": [
    "## Multi-threading: is it always worth it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63704d16-69b4-4f8f-9436-0fcfc4a0cf71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "function overhead!(v)\n",
    "    for idx in eachindex(v)\n",
    "        v[idx] = idx\n",
    "    end\n",
    "end\n",
    "\n",
    "# Write a function equivalent to the one above, but with a `@threads`-ed `for` loop.\n",
    "function overhead_threads!(v)\n",
    "    # ....\n",
    "end\n",
    "\n",
    "N = 10\n",
    "\n",
    "@btime overhead!(v) setup=(v = Vector{Int}(undef, N))\n",
    "@btime overhead_threads!(v) setup=(v = Vector{Int}(undef, N))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91a613-b722-48d7-95c3-6123629bfb13",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "  <strong>Multi-threading overhead</strong> <br />Since each iteration of the <tt>for</tt> loops above is very fast (single memory copy), what you are measuring when running <tt>overhead_threads!</tt> is basically the overhead of spawning <tt>Threads.nthreads()</tt> tasks.\n",
    "    The cost of spawning tasks is of the order of ~microseconds, so to make multi-threading beneficial you need to make sure each iteration/task is computationally intensive enough to overcome the cost of spawning tasks in the first place.\n",
    "    This is the reason why we iterated over larger chunks of data in the examples above, and performed some operations on it: we wanted to do some substantial computation in each iteration/task, to make the parallelisation efficient.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb49a61-dc01-430e-bc1a-3132b193c560",
   "metadata": {},
   "source": [
    "***Bonus***: do you see any improvement in the parallel efficiency if you change the size of the problem (here: `N`)? Can you think of a better strategy for this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d824e83-278b-4e6a-b1f8-4f0ce5e93940",
   "metadata": {},
   "source": [
    "## Unbalanced workload: computing hexadecimal $\\pi$\n",
    "\n",
    "_This section is inspired by the blogpost [Computing the hexadecimal value of pi](https://giordano.github.io/blog/2017-11-21-hexadecimal-pi/) by Mosè Giordano._\n",
    "\n",
    "The [Bailey–Borwein–Plouffe formula](https://en.wikipedia.org/wiki/Bailey%E2%80%93Borwein%E2%80%93Plouffe_formula) is one of the [several algorithms to compute $\\pi$](https://en.wikipedia.org/wiki/Approximations_of_%CF%80):\n",
    "\n",
    "$$\n",
    "\\pi = \\sum_{k = 0}^{\\infty}\\left[ \\frac{1}{16^k} \\left( \\frac{4}{8k + 1} -\n",
    "\\frac{2}{8k + 4} - \\frac{1}{8k + 5} - \\frac{1}{8k + 6} \\right) \\right]\n",
    "$$\n",
    "\n",
    "What makes this formula stand out among other approximations of $\\pi$ is that it allows one to directly extract the $n$-th fractional digit of the hexadecimal value of $\\pi$ without computing the preceding ones.\n",
    "\n",
    "The Wikipedia article about the Bailey–Borwein–Plouffe formula explains that the $n + 1$-th fractional digit $d_n$ is given by\n",
    "\n",
    "$$\n",
    "d_{n} = 16 \\left[ 4 \\Sigma(n, 1) - 2 \\Sigma(n, 4) - \\Sigma(n, 5) - \\Sigma(n,\n",
    "6) \\right]\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\Sigma(n, j) = \\sum_{k = 0}^{n} \\frac{16^{n-k} \\bmod (8k+j)}{8k+j} + \\sum_{k\n",
    "= n+1}^{\\infty} \\frac{16^{n-k}}{8k+j}\n",
    "$$\n",
    "\n",
    "Only the fractional part of expression in square brackets on the right side of $d_n$ is relevant, thus, in order to avoid rounding errors, when we compute each term of the finite sum above we can take only the fractional part. This allows us to always use ordinary double precision floating-point arithmetic, without resorting to arbitrary-precision numbers. In addition note that the terms of the infinite sum get quickly very small, so we can stop the summation when they become negligible.\n",
    "\n",
    "### Serial implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa121014-046d-4fdc-9be9-d8bed49285de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Return the fractional part of x, modulo 1, always positive\n",
    "fpart(x) = mod(x, one(x))\n",
    "\n",
    "function Σ(n, j)\n",
    "    # Compute the finite sum\n",
    "    s = 0.0\n",
    "    denom = j\n",
    "    for k in 0:n\n",
    "        s = fpart(s + powermod(16, n - k, denom) / denom)\n",
    "        denom += 8\n",
    "    end\n",
    "    # Compute the infinite sum\n",
    "    num = 1 / 16\n",
    "    while (frac = num / denom) > eps(s)\n",
    "        s     += frac\n",
    "        num   /= 16\n",
    "        denom += 8\n",
    "    end\n",
    "    return fpart(s)\n",
    "end\n",
    "\n",
    "pi_digit(n) =\n",
    "    floor(Int, 16 * fpart(4Σ(n-1, 1) - 2Σ(n-1, 4) - Σ(n-1, 5) - Σ(n-1, 6)))\n",
    "\n",
    "pi_string(n) = \"0x3.\" * join(string.(pi_digit.(1:n); base = 16)) * \"p0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62292be8-4c5b-4112-a207-e9148874d578",
   "metadata": {},
   "source": [
    "Let's make sure this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d3e6f-0b07-430e-8f99-460725b47c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pi_string(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9a23ba-70d4-474b-9cd5-bdb84d4e3d93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parse the string as a double-precision floating point number\n",
    "parse(Float64, pi_string(13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea6ef16-6f47-47e9-867d-b1153fab396c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Float64(π) == parse(Float64, pi_string(13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fbbc5e-face-4582-a260-e619ed87835c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_pi = 1_000\n",
    "\n",
    "setprecision(BigFloat, 4 * N_pi) do\n",
    "    BigFloat(π) == parse(BigFloat, pi_string(N_pi))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e689e73d-531d-429c-b2f2-9b36a01833b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "b = @benchmark pi_string(N_pi)\n",
    "\n",
    "pi_serial_t = minimum(b.times)\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e91305-4c96-4c77-b3e2-e3e272475b33",
   "metadata": {},
   "source": [
    "### Multi-threaded implementation\n",
    "\n",
    "Since the Bailey–Borwtimesn–Plouffe formula extracts the $n$-th digit of $\\pi$ without computing the other ones, we can write a multi-threaded version of `pi_string`, taking advantage of native support for [multi-threading](https://docs.julialang.org/en/v1/manual/multi-threading/) in Julia. However note that the computational cost of `pi_digit` is $O(n\\log(n))$, so the larger the value of $n$, the longer the function will take, which makes this workload very unbalanced. ***Question***: what do you expect to be the best and worst performing schedulers?\n",
    "\n",
    "#### For-loop: static scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9b2ccb-3965-4dc2-95cb-3030ef49b314",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write a function which returns the same string as `pi_string(N_pi)`, using a `:static` multi-threaded `for` loop\n",
    "function pi_string_threads_static(N)\n",
    "    digits = Vector{Int}(undef, N)\n",
    "    @threads ... for n in eachindex(digits)\n",
    "        digits[n] = # ...\n",
    "    end\n",
    "    return \"0x3.\" * ... * \"p0\"\n",
    "end\n",
    "\n",
    "@assert pi_string_threads_static(N_pi) == pi_string(N_pi)\n",
    "\n",
    "b = @benchmark pi_string_threads_static(N_pi)\n",
    "\n",
    "pi_threads_static_t = minimum(b.times)\n",
    "\n",
    "display(b)\n",
    "\n",
    "@info \"parallel efficiency: $(round(pi_serial_t / pi_threads_static_t / nthreads() * 100; digits=2))%\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7892a693-4aa8-4ab0-8582-985bdf20cc23",
   "metadata": {},
   "source": [
    "#### For-loop: dynamic scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6c85a7-89fa-4afe-96f7-3c1dc5c99193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write a function which returns the same string as `pi_string(N_pi)`, using a `:dynamic` multi-threaded `for` loop\n",
    "function pi_string_threads_dynamic(N)\n",
    "    digits = Vector{Int}(undef, N)\n",
    "    @threads ... for n in eachindex(digits)\n",
    "        digits[n] = # ...\n",
    "    end\n",
    "    return \"0x3.\" * .... * \"p0\"\n",
    "end\n",
    "\n",
    "@assert pi_string_threads_dynamic(N_pi) == pi_string(N_pi)\n",
    "\n",
    "b = @benchmark pi_string_threads_dynamic(N_pi)\n",
    "\n",
    "pi_threads_dynamic_t = minimum(b.times)\n",
    "\n",
    "display(b)\n",
    "\n",
    "@info \"parallel efficiency: $(round(pi_serial_t / pi_threads_dynamic_t / nthreads() * 100; digits=2))%\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52201d41-ba3b-4492-976b-74555bf8ec1d",
   "metadata": {},
   "source": [
    "#### For-loop: greedy scheduler (only Julia v1.11+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8549cab0-3594-4568-bfb1-e2e8de454eac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@static if VERSION >= v\"1.11\"\n",
    "\n",
    "# Write a function which returns the same string as `pi_string(N_pi)`, using a `:greedy` multi-threaded `for` loop\n",
    "function pi_string_threads_greedy(N)\n",
    "    digits = Vector{Int}(undef, N)\n",
    "    @threads ... for n in eachindex(digits)\n",
    "        digits[n] = # ..\n",
    "    end\n",
    "    return \"0x3.\" * .... * \"p0\"\n",
    "end\n",
    "\n",
    "@assert pi_string_threads_greedy(N_pi) == pi_string(N_pi)\n",
    "\n",
    "b = @benchmark pi_string_threads_greedy(N_pi)\n",
    "\n",
    "pi_threads_greedy_t = minimum(b.times)\n",
    "\n",
    "display(b)\n",
    "\n",
    "@info \"parallel efficiency: $(round(pi_serial_t / pi_threads_greedy_t / nthreads() * 100; digits=2))%\"\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a7522c-7ae4-47e3-86dd-10e5b1977bd8",
   "metadata": {},
   "source": [
    "#### Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b5a4bc-31b4-4d70-aedf-89e539b69988",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write a function which returns the same string as `pi_string(N_pi)`, spawning tasks\n",
    "function pi_string_tasks(N)\n",
    "    tasks = map(n -> ..., 1:N)\n",
    "    return \"0x3.\" * ... * \"p0\"\n",
    "end\n",
    "\n",
    "@assert pi_string_tasks(N_pi) == pi_string(N_pi)\n",
    "\n",
    "b = @benchmark pi_string_tasks(N_pi)\n",
    "\n",
    "pi_tasks_t = minimum(b.times)\n",
    "\n",
    "display(b)\n",
    "\n",
    "@info \"parallel efficiency: $(round(pi_serial_t / pi_tasks_t / nthreads() * 100; digits=2))%\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d364c813-1f97-4aad-9207-a140126092a1",
   "metadata": {},
   "source": [
    "#### Bonus: using OhMyThreads.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69507e7-0c1e-4b39-bc50-005954a7d535",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong>Tip</strong> <br />\n",
    "  For this exercise you may want to have a look at the <a href=\"https://juliafolds2.github.io/OhMyThreads.jl/stable/refs/api/#OhMyThreads.@tasks\" class=\"alert-link\"><tt>OhMyThreads.@tasks</tt></a> macro, to be used in conjunction with <a href=\"https://juliafolds2.github.io/OhMyThreads.jl/stable/refs/api/#OhMyThreads.@set\" class=\"alert-link\"><tt>OhMyThreads.@set</tt></a>.\n",
    "  You can take a look at the <a href=\"https://juliafolds2.github.io/OhMyThreads.jl/stable/translation/\" class=\"alert-link\">translation guide</a> for inspiration.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939ed6ed-ca43-4c39-a364-61563b757528",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using OhMyThreads: @tasks, @set\n",
    "\n",
    "# Write a function which returns the same string as `pi_string(N_pi)`, using `OhMyThreads.@tasks` for parallelisation.\n",
    "function pi_string_omt(N; ntasks::Int=8 * nthreads(), scheduler::Symbol=:dynamic)\n",
    "    digits = Vector{Int}(undef, N)\n",
    "    @tasks for n in eachindex(digits)\n",
    "        @set ntasks=ntasks\n",
    "        @set scheduler=scheduler\n",
    "        # ...\n",
    "    end\n",
    "    return \"0x3.\" * .... * \"p0\"\n",
    "end\n",
    "\n",
    "@assert pi_string_omt(N_pi) == pi_string(N_pi)\n",
    "\n",
    "b = @benchmark pi_string_omt(N_pi; ntasks=32 * nthreads())\n",
    "\n",
    "pi_omt_t = minimum(b.times)\n",
    "\n",
    "display(b)\n",
    "\n",
    "@info \"parallel efficiency: $(round(pi_serial_t / pi_omt_t / nthreads() * 100; digits=2))%\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multithreaded Julia 1.12.1",
   "language": "julia",
   "name": "multithreaded-julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
